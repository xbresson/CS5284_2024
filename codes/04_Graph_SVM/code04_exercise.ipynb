{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture : Graph SVM\n",
    "\n",
    "## Lab 04 : Graph SVM -- Exercise\n",
    "\n",
    "### Xavier Bresson, Guoji Fu \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    path_to_file = '/content/gdrive/My Drive/CS5284_2024_codes/codes/04_Graph_SVM'\n",
    "    print(path_to_file)\n",
    "    # change current path to the folder containing \"path_to_file\"\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook \n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "import time\n",
    "import sys; sys.path.insert(0, 'lib/')\n",
    "from lib.utils import compute_purity\n",
    "from lib.utils import compute_SVM\n",
    "from lib.utils import construct_knn_graph\n",
    "from lib.utils import graph_laplacian\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import sklearn.metrics.pairwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "mat = scipy.io.loadmat('datasets/data_twomoons_graphSVM.mat')\n",
    "Xtrain = mat['Xtrain']\n",
    "Cgt_train = mat['Cgt_train'] - 1; Cgt_train = Cgt_train.squeeze()\n",
    "l_train = mat['l'].squeeze()\n",
    "nb_labeled_data_per_class = mat['nb_labeled_data_per_class'].squeeze()\n",
    "n = Xtrain.shape[0]\n",
    "d = Xtrain.shape[1]\n",
    "nc = len(np.unique(Cgt_train))\n",
    "print(n,d,nc)\n",
    "Xtest = mat['Xtest']\n",
    "Cgt_test = mat['Cgt_test'] - 1; Cgt_test = Cgt_test.squeeze()\n",
    "print('l_train:',l_train)\n",
    "print('number of labeled data per class:',nb_labeled_data_per_class)\n",
    "print('number of unlabeled data:',n-2*nb_labeled_data_per_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(12,4))\n",
    "p1 = plt.subplot(121)\n",
    "size_vertex_plot = 33\n",
    "plt.scatter(Xtrain[:,0], Xtrain[:,1], s=size_vertex_plot*np.ones(n), c=l_train, color=pyplot.jet())\n",
    "plt.title('Training Data: Labeled Data in red (first class)\\n and blue (second class), \\n and unlabeled Data in green (data geometry)')\n",
    "plt.colorbar()\n",
    "p2 = plt.subplot(122)\n",
    "size_vertex_plot = 33\n",
    "plt.scatter(Xtest[:,0], Xtest[:,1], s=size_vertex_plot*np.ones(n), c=Cgt_test, color=pyplot.jet())\n",
    "plt.title('Test Data')\n",
    "plt.colorbar()\n",
    "#plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run kernel SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe the solution provided by kernel SVM with a limited number of 2 labels\n",
    "\n",
    "What was the accuracy when using a larger number of labels, i.e. code03? \n",
    "\n",
    "Answer: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run kernel SVM\n",
    "\n",
    "# Compute Gaussian kernel, L, Q\n",
    "sigma = 0.5; sigma2 = sigma**2\n",
    "Ddist = sklearn.metrics.pairwise.pairwise_distances(Xtrain, Xtrain, metric='euclidean', n_jobs=1)\n",
    "Ker = np.exp(- Ddist**2 / sigma2)\n",
    "Ddist = sklearn.metrics.pairwise.pairwise_distances(Xtrain, Xtest, metric='euclidean', n_jobs=1)\n",
    "KXtest = np.exp(- Ddist**2 / sigma2)\n",
    "l = l_train\n",
    "L = np.diag(l)\n",
    "Q = L.dot(Ker.dot(L))\n",
    "\n",
    "# Time steps\n",
    "tau_alpha = 10/ np.linalg.norm(Q,2)\n",
    "tau_beta = 0.1/ np.linalg.norm(L,2)\n",
    "\n",
    "# For conjuguate gradient\n",
    "Acg = tau_alpha* Q + np.eye(n)\n",
    "\n",
    "# Pre-compute J.K(Xtest) for test data\n",
    "LKXtest = L.dot(KXtest)\n",
    "\n",
    "# Error parameter\n",
    "lamb = 3 # acc: 73.8\n",
    "\n",
    "# Initialization\n",
    "alpha = np.zeros([n])\n",
    "beta = 0.0\n",
    "alpha_old = alpha\n",
    "\n",
    "# Loop\n",
    "k = 0\n",
    "diff_alpha = 1e6\n",
    "num_iter = 201\n",
    "while (diff_alpha>1e-3) & (k<num_iter):\n",
    "    \n",
    "    # Update iteration\n",
    "    k += 1\n",
    "    \n",
    "    # Update alpha\n",
    "    # Approximate solution with conjuguate gradient\n",
    "    b0 = alpha + tau_alpha - tau_alpha* l* beta\n",
    "    alpha, _ = scipy.sparse.linalg.cg(Acg, b0, x0=alpha, tol=1e-3, maxiter=50)   \n",
    "    alpha[alpha<0.0] = 0 # Projection on [0,+infty]\n",
    "    alpha[alpha>lamb] = lamb # Projection on [-infty,lamb]\n",
    "\n",
    "    # Update beta\n",
    "    beta = beta + tau_beta* l.T.dot(alpha)\n",
    "    \n",
    "    # Stopping condition\n",
    "    diff_alpha = np.linalg.norm(alpha-alpha_old)\n",
    "    alpha_old = alpha\n",
    "    \n",
    "    # Plot\n",
    "    if not(k%100) or (diff_alpha<1e-3):\n",
    "           \n",
    "        # Indicator function of support vectors\n",
    "        idx = np.where( np.abs(alpha)>0.25* np.max(np.abs(alpha)) )\n",
    "        Isv = np.zeros([n]); Isv[idx] = 1\n",
    "        nb_sv = len(Isv.nonzero()[0])\n",
    "        \n",
    "        # Offset\n",
    "        if nb_sv > 1:\n",
    "            b = (Isv.T).dot( l - Ker.dot(L.dot(alpha)) )/ nb_sv\n",
    "        else:\n",
    "            b = 0\n",
    "            \n",
    "        # Continuous score function\n",
    "        f_test = alpha.T.dot(LKXtest) + b \n",
    "\n",
    "        # Binary classification function\n",
    "        C_test = np.sign(f_test) # decision function in {-1,1}\n",
    "        accuracy_test = compute_purity(0.5*(1+C_test),Cgt_test,nc) # 0.5*(1+C_test) in {0,1}\n",
    "\n",
    "        # Plot\n",
    "        size_vertex_plot = 33\n",
    "        plt.figure(figsize=(12,4))\n",
    "        p1 = plt.subplot(121)\n",
    "        plt.scatter(Xtest[:,0], Xtest[:,1], s=size_vertex_plot*np.ones(n), c=f_test, color=pyplot.jet())\n",
    "        plt.title('Score function $s(x)=w^T\\phi(x)+b$ \\n iter=' + str(k)+ ', diff_alpha=' + str(diff_alpha)[:7])\n",
    "        plt.colorbar()\n",
    "        p2 = plt.subplot(122)\n",
    "        plt.scatter(Xtest[:,0], Xtest[:,1], s=size_vertex_plot*np.ones(n), c=C_test, color=pyplot.jet())\n",
    "        plt.title('Classification function $f(x)=sign(w^T\\phi(x)+b)$\\n iter=' + str(k) + ', acc=' + str(accuracy_test)[:5])\n",
    "        #plt.tight_layout()\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        if k<num_iter-1:\n",
    "            clear_output(wait=True)   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Graph SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Gaussian kernel \n",
    "sigma = 0.15; sigma2 = sigma**2\n",
    "Ddist = sklearn.metrics.pairwise.pairwise_distances(Xtrain, Xtrain, metric='euclidean', n_jobs=1)\n",
    "Ker = np.exp(- Ddist**2 / sigma2)\n",
    "Ddist = sklearn.metrics.pairwise.pairwise_distances(Xtrain, Xtest, metric='euclidean', n_jobs=1)\n",
    "KXtest = np.exp(- Ddist**2 / sigma2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 : Construct a KNN graph from training data and compute the Laplacian matrix\n",
    "\n",
    "You may use `A = construct_knn_graph(data, k, dist_metric)` to generate the adjacency matrix of a KNN graph from a training dataset.\n",
    "\n",
    "Usage:\n",
    "- `data`: The features of the training data.\n",
    "- `k`: The number of nearest neighbors.\n",
    "- `dist_metric`: The distance matric, e.g., using the Euclidean distance `'euclidean'`, `'euclidean_zelnik_perona'` or `'cosine'`.\n",
    "- `A`: The adjacency matrix of the KNN graph.\n",
    "\n",
    "You may consider `Lap = graph_laplacian(A).todense()` to obtain the Laplacian matrix from an adjacency matrix `A`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute kNN graph\n",
    "############################################################################\n",
    "# Your code start\n",
    "############################################################################\n",
    "\n",
    "kNN = \n",
    "A = construct_knn_graph()\n",
    "Lap = graph_laplacian().todense()\n",
    "\n",
    "############################################################################\n",
    "# Your code end\n",
    "############################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Compute the indicator function of labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Indicator function of labels\n",
    "############################################################################\n",
    "# Your code start\n",
    "############################################################################\n",
    "\n",
    "H = \n",
    "\n",
    "############################################################################\n",
    "# Your code end\n",
    "############################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Compute L, Q for graph SVM\n",
    "\n",
    "Refer to Lecture 4 Page 50:\n",
    "\n",
    "- $L = \\text{Diag}(l)$\n",
    "- $Q = LHK(I+\\gamma \\mathcal{L}K)^{-1}HL$\n",
    "\n",
    "You may use these functions:\n",
    "* `np.diag()`: Diagonal matrix from a vector.\n",
    "* `np.eye()`: Identity matrix.\n",
    "* `np.linalg.inv()`: Inverse matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute L, Q\n",
    "############################################################################\n",
    "# Your code start\n",
    "############################################################################\n",
    "\n",
    "gamma = 25 # weight of the graph loss\n",
    "l = l_train\n",
    "L = \n",
    "Q = \n",
    "\n",
    "############################################################################\n",
    "# Your code end\n",
    "############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Graph SVM\n",
    "\n",
    "# Time steps\n",
    "tau_alpha = 1/ np.linalg.norm(Q,2)\n",
    "tau_beta = 1/ np.linalg.norm(L,2)\n",
    "\n",
    "# For conjuguate gradient\n",
    "Acg = tau_alpha* Q + np.eye(n)\n",
    "\n",
    "# Error parameter\n",
    "lamb = 1 # acc: 98.6\n",
    "\n",
    "# Initialization\n",
    "alpha = np.zeros([n])\n",
    "beta = np.zeros([n])\n",
    "alpha_old = alpha\n",
    "\n",
    "# Loop\n",
    "k = 0\n",
    "diff_alpha = 1e6\n",
    "num_iter = 201\n",
    "while (diff_alpha>1e-3) & (k<num_iter):\n",
    "    \n",
    "    # Update iteration\n",
    "    k += 1\n",
    "    \n",
    "    # Update alpha\n",
    "    # Approximate solution with conjuguate gradient\n",
    "    b0 = alpha + tau_alpha - tau_alpha* l* beta\n",
    "    alpha, _ = scipy.sparse.linalg.cg(Acg, b0, x0=alpha, tol=1e-3, maxiter=50)   \n",
    "    alpha[alpha<0.0] = 0 # Projection on [0,+infty]\n",
    "    alpha[alpha>lamb] = lamb # Projection on [-infty,lamb]\n",
    "\n",
    "    # Update beta\n",
    "    beta = beta + tau_beta* l.T.dot(alpha)\n",
    "    \n",
    "    # Stopping condition\n",
    "    diff_alpha = np.linalg.norm(alpha-alpha_old)\n",
    "    alpha_old = alpha\n",
    "    \n",
    "    # Plot\n",
    "    if not(k%100) or (diff_alpha<1e-3):\n",
    "        \n",
    "        # xi vector\n",
    "        xi = Tinv.dot(H.dot(L.dot(alpha)))\n",
    "\n",
    "        # Offset\n",
    "        idx_unlabeled_data = np.where( np.abs(l)<1./2 )\n",
    "        alpha_labels = alpha; alpha_labels[idx_unlabeled_data] = 0\n",
    "        idx = np.where( np.abs(alpha_labels)>0.25* np.max(np.abs(alpha_labels)) )\n",
    "        Isv = np.zeros([n]); Isv[idx] = 1 # Indicator function of Support Vectors\n",
    "        nb_sv = len(Isv.nonzero()[0])\n",
    "        if nb_sv > 1:\n",
    "            b = (Isv.T).dot( l - Ker.dot(np.squeeze(np.array(xi))) )/ nb_sv\n",
    "        else:\n",
    "            b = 0        \n",
    "            \n",
    "        # Continuous score function\n",
    "        f_test = np.squeeze(np.array(xi.dot(KXtest) + b))\n",
    "\n",
    "        # Binary classification function\n",
    "        C_test = np.sign(f_test) # decision function in {-1,1}\n",
    "        print('C_test',C_test.shape)\n",
    "        accuracy_test = compute_purity(0.5*(1+C_test),Cgt_test,nc) # 0.5*(1+C_test) in {0,1}\n",
    "\n",
    "        # Plot\n",
    "        size_vertex_plot = 33\n",
    "        plt.figure(figsize=(12,4))\n",
    "        p1 = plt.subplot(121)\n",
    "        plt.scatter(Xtest[:,0], Xtest[:,1], s=size_vertex_plot*np.ones(n), c=f_test, color=pyplot.jet())\n",
    "        plt.title('Score function $s(x)=w^T\\phi(x)+b$ \\n iter=' + str(k)+ ', diff_alpha=' + str(diff_alpha)[:7])\n",
    "        plt.colorbar()\n",
    "        p2 = plt.subplot(122)\n",
    "        plt.scatter(Xtest[:,0], Xtest[:,1], s=size_vertex_plot*np.ones(n), c=C_test, color=pyplot.jet())\n",
    "        plt.title('Classification function $f(x)=sign(w^T\\phi(x)+b)$\\n iter=' + str(k) + ', acc=' + str(accuracy_test)[:5])\n",
    "        #plt.tight_layout()\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        if k<num_iter-1:\n",
    "            clear_output(wait=True)   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-world graph of articles\n",
    "\n",
    "# Dataset has 10 labeled data and 40 unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "mat = scipy.io.loadmat('datasets/data_20news_10labels_40unlabels.mat')\n",
    "Xtrain = mat['Xtrain']\n",
    "n = Xtrain.shape[0]\n",
    "l_train = mat['l'].squeeze()\n",
    "d = Xtrain.shape[1]\n",
    "Xtest = mat['Xtest']\n",
    "Cgt_test = mat['Cgt_test'] - 1; Cgt_test = Cgt_test.squeeze()\n",
    "nc = len(np.unique(Cgt_test))\n",
    "print(n,d,nc)\n",
    "num_labels = np.sum(np.abs(l_train)>0.0)\n",
    "print('l_train:',l_train)\n",
    "print('number of labeled data per class:',num_labels//2)\n",
    "print('number of unlabeled data:',n-num_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Kernel SVM (no graph information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Kernel SVM (no graph information)\n",
    "\n",
    "# Compute Gaussian kernel \n",
    "sigma = 0.5; sigma2 = sigma**2\n",
    "Ddist = sklearn.metrics.pairwise.pairwise_distances(Xtrain, Xtrain, metric='euclidean', n_jobs=1)\n",
    "Ker = np.exp(- Ddist**2 / sigma2)\n",
    "Ddist = sklearn.metrics.pairwise.pairwise_distances(Xtrain, Xtest, metric='euclidean', n_jobs=1)\n",
    "KXtest = np.exp(- Ddist**2 / sigma2)\n",
    "\n",
    "# Compute kNN graph\n",
    "kNN = 5\n",
    "gamma = 0 # <= no graph information\n",
    "A = construct_knn_graph(Xtrain, kNN, 'cosine')\n",
    "Lap = graph_laplacian(A).todense()\n",
    "\n",
    "# Compute Indicator function of labels\n",
    "H = np.zeros([n])\n",
    "H[np.abs(l_train)>0.0] = 1\n",
    "H = np.diag(H)\n",
    "\n",
    "# Compute L, Q\n",
    "L = np.diag(l_train)\n",
    "l = l_train\n",
    "T = np.eye(n)\n",
    "T += gamma* Lap.dot(Ker) \n",
    "Tinv = np.linalg.inv(T)\n",
    "Q = L.dot(H.dot(Ker.dot(Tinv.dot(H.dot(L)))))\n",
    "\n",
    "# Time steps\n",
    "tau_alpha = 1/ np.linalg.norm(Q,2)\n",
    "tau_beta = 1/ np.linalg.norm(L,2)\n",
    "\n",
    "# For conjuguate gradient\n",
    "Acg = tau_alpha* Q + 1* np.eye(n)\n",
    "\n",
    "# Error parameter\n",
    "lamb = 100 \n",
    "\n",
    "# Initialization\n",
    "alpha = np.zeros([n])\n",
    "beta = 0.0\n",
    "alpha_old = alpha\n",
    "\n",
    "# Loop\n",
    "k = 0\n",
    "diff_alpha = 1e6\n",
    "num_iter = 1001\n",
    "while (diff_alpha>1e-3) & (k<num_iter):\n",
    "    \n",
    "    # Update iteration\n",
    "    k += 1\n",
    "    \n",
    "    # Update alpha\n",
    "    # Approximate solution with conjuguate gradient\n",
    "    b0 = alpha + tau_alpha - tau_alpha* l* beta\n",
    "    alpha, _ = scipy.sparse.linalg.cg(Acg, b0, x0=alpha, tol=1e-3, maxiter=50)   \n",
    "    alpha[alpha<0.0] = 0 # Projection on [0,+infty]\n",
    "    alpha[alpha>lamb] = lamb # Projection on [-infty,lamb]\n",
    "\n",
    "    # Update beta\n",
    "    beta = beta + tau_beta* l.T.dot(alpha)\n",
    "    \n",
    "    # Stopping condition\n",
    "    diff_alpha = np.linalg.norm(alpha-alpha_old)\n",
    "    alpha_old = alpha\n",
    "    \n",
    "    # Plot\n",
    "    if not(k%100) or (diff_alpha<1e-3):\n",
    "        \n",
    "        # xi vector\n",
    "        xi = Tinv.dot(H.dot(L.dot(alpha)))\n",
    "\n",
    "        # Offset\n",
    "        idx_unlabeled_data = np.where( np.abs(l)<1./2 )\n",
    "        alpha_labels = alpha; alpha_labels[idx_unlabeled_data] = 0\n",
    "        idx = np.where( np.abs(alpha_labels)>0.25* np.max(np.abs(alpha_labels)) )\n",
    "        Isv = np.zeros([n]); Isv[idx] = 1 # Indicator function of Support Vectors\n",
    "        nb_sv = len(Isv.nonzero()[0])\n",
    "        if nb_sv > 1:\n",
    "            b = (Isv.T).dot( l - Ker.dot(np.squeeze(np.array(xi))) )/ nb_sv\n",
    "        else:\n",
    "            b = 0        \n",
    "            \n",
    "        # Continuous score function\n",
    "        f_test = xi.dot(KXtest) + b\n",
    "\n",
    "        # Binary classification function\n",
    "        C_test = np.sign(f_test) # decision function in {-1,1}\n",
    "        accuracy_test = compute_purity(0.5*(1+C_test),Cgt_test,nc) # 0.5*(1+C_test) in {0,1}\n",
    "\n",
    "        # Print\n",
    "        # print('iter, diff_alpha',str(k),str(diff_alpha)[:7])\n",
    "        # print('acc',str(accuracy_test)[:5])\n",
    "\n",
    "print('Kernel SVM  iter, diff_alpha :',str(k),str(diff_alpha)[:7])\n",
    "print('            acc :',str(accuracy_test)[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Graph SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Compare the results with kernel SVM and deduce the implications of graph SVM outperforming kernel SVM on real-world data?\n",
    "\n",
    "Answer: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Graph SVM\n",
    "\n",
    "# Compute Gaussian kernel \n",
    "sigma = 0.5; sigma2 = sigma**2\n",
    "Ddist = sklearn.metrics.pairwise.pairwise_distances(Xtrain, Xtrain, metric='euclidean', n_jobs=1)\n",
    "Ker = np.exp(- Ddist**2 / sigma2)\n",
    "Ddist = sklearn.metrics.pairwise.pairwise_distances(Xtrain, Xtest, metric='euclidean', n_jobs=1)\n",
    "KXtest = np.exp(- Ddist**2 / sigma2)\n",
    "\n",
    "# Compute kNN graph\n",
    "kNN = 8\n",
    "gamma = 100\n",
    "A = construct_knn_graph(Xtrain, kNN, 'cosine')\n",
    "Lap = graph_laplacian(A).todense()\n",
    "\n",
    "# Compute Indicator function of labels\n",
    "H = np.zeros([n])\n",
    "H[np.abs(l_train)>0.0] = 1\n",
    "H = np.diag(H)\n",
    "\n",
    "# Compute L, Q\n",
    "L = np.diag(l_train)\n",
    "l = l_train\n",
    "T = np.eye(n)\n",
    "T += gamma* Lap.dot(Ker) \n",
    "Tinv = np.linalg.inv(T)\n",
    "Q = L.dot(H.dot(Ker.dot(Tinv.dot(H.dot(L)))))\n",
    "\n",
    "# Time steps\n",
    "tau_alpha = 1/ np.linalg.norm(Q,2)\n",
    "tau_beta = 1/ np.linalg.norm(L,2)\n",
    "\n",
    "# For conjuguate gradient\n",
    "Acg = tau_alpha* Q + 1* np.eye(n)\n",
    "\n",
    "# Error parameter\n",
    "lamb = 1\n",
    "\n",
    "# Initialization\n",
    "alpha = np.zeros([n])\n",
    "beta = 0.0\n",
    "alpha_old = alpha\n",
    "\n",
    "# Loop\n",
    "k = 0\n",
    "diff_alpha = 1e6\n",
    "num_iter = 1001\n",
    "while (diff_alpha>1e-3) & (k<num_iter):\n",
    "    \n",
    "    # Update iteration\n",
    "    k += 1\n",
    "    \n",
    "    # Update alpha\n",
    "    # Approximate solution with conjuguate gradient\n",
    "    b0 = alpha + tau_alpha - tau_alpha* l* beta\n",
    "    alpha, _ = scipy.sparse.linalg.cg(Acg, b0, x0=alpha, tol=1e-3, maxiter=50)   \n",
    "    alpha[alpha<0.0] = 0 # Projection on [0,+infty]\n",
    "    alpha[alpha>lamb] = lamb # Projection on [-infty,lamb]\n",
    "\n",
    "    # Update beta\n",
    "    beta = beta + tau_beta* l.T.dot(alpha)\n",
    "    \n",
    "    # Stopping condition\n",
    "    diff_alpha = np.linalg.norm(alpha-alpha_old)\n",
    "    alpha_old = alpha\n",
    "    \n",
    "    # Plot\n",
    "    if not(k%100) or (diff_alpha<1e-3):\n",
    "        \n",
    "        # xi vector\n",
    "        xi = Tinv.dot(H.dot(L.dot(alpha)))\n",
    "\n",
    "        # Offset\n",
    "        idx_unlabeled_data = np.where( np.abs(l)<1./2 )\n",
    "        alpha_labels = alpha; alpha_labels[idx_unlabeled_data] = 0\n",
    "        idx = np.where( np.abs(alpha_labels)>0.25* np.max(np.abs(alpha_labels)) )\n",
    "        Isv = np.zeros([n]); Isv[idx] = 1 # Indicator function of Support Vectors\n",
    "        nb_sv = len(Isv.nonzero()[0])\n",
    "        if nb_sv > 1:\n",
    "            b = (Isv.T).dot( l - Ker.dot(np.squeeze(np.array(xi))) )/ nb_sv\n",
    "        else:\n",
    "            b = 0        \n",
    "            \n",
    "        # Continuous score function\n",
    "        f_test = xi.dot(KXtest) + b\n",
    "\n",
    "        # Binary classification function\n",
    "        C_test = np.sign(f_test) # decision function in {-1,1}\n",
    "        accuracy_test = compute_purity(0.5*(1+C_test),Cgt_test,nc) # 0.5*(1+C_test) in {0,1}\n",
    "\n",
    "        # Print\n",
    "        # print('iter, diff_alpha',str(k),str(diff_alpha)[:7])\n",
    "        # print('acc',str(accuracy_test)[:5])\n",
    "\n",
    "print('Graph SVM  iter, diff_alpha :',str(k),str(diff_alpha)[:7])\n",
    "print('           acc :',str(accuracy_test)[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot graph of test data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph of test data points\n",
    "kNN = 8 \n",
    "A = construct_knn_graph(Xtest, kNN, 'cosine')\n",
    "print(type(A),A.shape)\n",
    "\n",
    "import networkx as nx\n",
    "A.setdiag(0) \n",
    "A.eliminate_zeros()\n",
    "G_nx = nx.from_scipy_sparse_array(A)\n",
    "plt.figure(figsize=[40,40])\n",
    "nx.draw_networkx(G_nx, with_labels=True, node_color=np.array(C_test), cmap='jet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
